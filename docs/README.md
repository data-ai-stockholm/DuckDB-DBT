# Weather Data Pipeline with DuckDB, dbt & Apache Iceberg

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Poetry](https://img.shields.io/badge/dependency-poetry-purple)](https://python-poetry.org/)
[![DuckDB](https://img.shields.io/badge/DuckDB-1.4.2+-yellow)](https://duckdb.org/)
[![dbt](https://img.shields.io/badge/dbt-1.10+-orange)](https://www.getdbt.com/)
[![Prefect](https://img.shields.io/badge/Prefect-3.6+-blue)](https://www.prefect.io/)
[![Apache Iceberg](https://img.shields.io/badge/Iceberg-REST-green)](https://iceberg.apache.org/)

Modern data pipeline demonstrating **DuckDB**, **dbt**, and **Apache Iceberg** integration with **Polaris REST catalog** support.

> üéØ **Production-ready** data engineering project showcasing modern lakehouse architecture, workflow orchestration, and CI/CD best practices.

## Features

- ‚úÖ **Apache Iceberg Polaris** - Production-grade REST catalog (AWS, Nessie, self-hosted)
- ‚úÖ **Custom REST Catalog** - Educational implementation of Apache Iceberg REST spec
- ‚úÖ **DuckDB Integration** - Native Iceberg support with DuckDB v1.4.2+
- ‚úÖ **dbt Transformations** - Data modeling and transformations
- ‚úÖ **Prefect Orchestration** - Production-ready workflow orchestration with scheduling
- ‚úÖ **GitHub Actions CI/CD** - Automated testing, linting, and deployment
- ‚úÖ **Multi-Cloud Ready** - Supports local, S3, Azure Blob Storage, GCS
- ‚úÖ **Poetry** - Modern Python dependency management

## Quick Start

### Super Simple with Make

```bash
# 1. Setup
make setup

# 2. Start everything (Prefect UI + Catalog + Deployments)
make start

# 3. Open browser to http://localhost:4200

# 4. Run demo
make demo

# 5. Stop when done
make stop
```

### Common Make Commands

```bash
# Data Operations
make fetch-all      # Fetch all weather data
make dbt-all        # Run all dbt tasks

# Individual Flows
make run-weather    # Weather ingestion only
make run-dbt        # dbt transformations only
make run-pipeline   # Complete pipeline

# Development
make lint           # Run linting
make format         # Format code
make test           # Run tests

# Cleanup
make clean          # Stop servers + cleanup
make clean-data     # Delete warehouse data (WARNING!)
```

Run `make help` to see all available commands.

### Alternative: Manual Commands

<details>
<summary>Click to expand manual setup instructions</summary>

#### 1. Install Dependencies
```bash
poetry install
```

#### 2. Start REST Catalog Server
```bash
poetry run catalog-server
```

#### 3. Run Demo
```bash
poetry run python examples/test_catalog.py
```

#### 4. Fetch Real Weather Data (Optional)
```bash
poetry run fetch-stations
poetry run fetch-observations
poetry run load-observations
```

#### 5. Run dbt Transformations
```bash
poetry run dbt run --project-dir dbt --profiles-dir dbt
poetry run dbt test --project-dir dbt --profiles-dir dbt
```

#### 6. Orchestration with Prefect
```bash
# Start Prefect server
poetry run prefect server start

# Run flows
poetry run python src/flows/weather_ingestion.py
poetry run python src/flows/dbt_transformations.py
```

</details>

### For Production: Using Apache Iceberg Polaris

The above quick start uses a local catalog. For production deployments, use **Apache Iceberg Polaris** (managed or self-hosted REST catalog):

**See [POLARIS_SETUP.md](POLARIS_SETUP.md) for detailed instructions:**
- ‚úÖ AWS managed Polaris service
- ‚úÖ Self-hosted Polaris deployment
- ‚úÖ Nessie (alternative REST catalog)
- ‚úÖ Multi-cloud storage configuration (S3, Azure, GCS)

## Project Structure

```
duckdb-dbt/
‚îú‚îÄ‚îÄ .github/workflows/           # CI/CD pipelines
‚îÇ   ‚îú‚îÄ‚îÄ ci.yml                   # Main CI workflow
‚îÇ   ‚îî‚îÄ‚îÄ dbt.yml                  # dbt validation
‚îú‚îÄ‚îÄ config/                      # Application configuration
‚îÇ   ‚îî‚îÄ‚îÄ storage.yaml            # Multi-backend storage config
‚îú‚îÄ‚îÄ dbt/                         # dbt configuration & models
‚îÇ   ‚îú‚îÄ‚îÄ dbt_project.yml         # dbt project configuration
‚îÇ   ‚îú‚îÄ‚îÄ profiles.yml            # dbt profiles
‚îÇ   ‚îî‚îÄ‚îÄ models/                 # dbt transformations
‚îÇ       ‚îú‚îÄ‚îÄ staging/            # Staging models
‚îÇ       ‚îî‚îÄ‚îÄ marts/              # Business logic models
‚îú‚îÄ‚îÄ docs/                        # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ README.md               # User guide (this file)
‚îÇ   ‚îî‚îÄ‚îÄ CLAUDE.md               # Technical deep-dive
‚îú‚îÄ‚îÄ scripts/                     # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ deploy_flows.py         # Prefect deployment script
‚îÇ   ‚îî‚îÄ‚îÄ run_with_ui.sh          # UI runner script
‚îú‚îÄ‚îÄ src/                         # Source code
‚îÇ   ‚îú‚îÄ‚îÄ catalog/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rest_server.py      # Custom Iceberg REST catalog
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py           # Configuration management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ iceberg_manager.py  # DuckDB Iceberg integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fetch_stations.py   # Weather station fetcher
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fetch_observations.py # Weather data fetcher
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ write_observations.py # Data loader
‚îÇ   ‚îî‚îÄ‚îÄ flows/                  # Prefect orchestration flows
‚îÇ       ‚îú‚îÄ‚îÄ demo_flow.py        # Demo flow
‚îÇ       ‚îú‚îÄ‚îÄ weather_ingestion.py # Data ingestion flow
‚îÇ       ‚îú‚îÄ‚îÄ dbt_transformations.py # dbt flow
‚îÇ       ‚îî‚îÄ‚îÄ main_pipeline.py    # Complete pipeline
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îî‚îÄ‚îÄ test_catalog.py         # Demo script
‚îú‚îÄ‚îÄ prefect.yaml                 # Prefect deployments
‚îú‚îÄ‚îÄ pyproject.toml               # Poetry dependencies
‚îú‚îÄ‚îÄ Makefile                     # Build automation
‚îî‚îÄ‚îÄ warehouse/                   # Iceberg data lake (gitignored)
```

## Configuration

Edit `config/storage.yaml` to configure storage backends and catalog settings:

```yaml
# Storage: local, s3, azure, gcs
storage:
  backend: local

# Table format: duckdb or iceberg
table_format: iceberg

# Iceberg REST catalog
iceberg:
  catalog:
    type: rest
    uri: http://localhost:8181
```

## Commands

```bash
# Start catalog server
poetry run catalog-server

# Fetch weather data
poetry run fetch-stations
poetry run fetch-observations

# Load data to Iceberg
poetry run load-observations

# Run dbt
poetry run dbt run --project-dir dbt --profiles-dir dbt
poetry run dbt test --project-dir dbt --profiles-dir dbt
```

## What's Inside

### Custom REST Catalog

A complete implementation of the Apache Iceberg REST Catalog specification:
- Namespace management (create, list, delete)
- Table operations (create, read, update, delete)
- Proper schema conversion (REST ‚Üî PyIceberg)
- Complex type handling (lists, structs, maps)
- Snapshot and metadata management

### Iceberg Table Format

Real Iceberg tables with proper structure:
```
warehouse/
‚îî‚îÄ‚îÄ weather_data.db/
    ‚îî‚îÄ‚îÄ observations/
        ‚îú‚îÄ‚îÄ data/
        ‚îÇ   ‚îî‚îÄ‚îÄ *.parquet          # Data files
        ‚îî‚îÄ‚îÄ metadata/
            ‚îú‚îÄ‚îÄ *.metadata.json    # Schema + snapshots
            ‚îî‚îÄ‚îÄ *.avro             # Manifests
```

### dbt Models

**Staging Layer:**
- **stg_observations** - Cleaned weather observations from source

**Marts Layer:**
- **fact_observations** - Enriched observations with temporal attributes
- **fact_daily_weather** - Daily weather aggregates by station
- **dim_stations** - Station dimension table
- **extreme_weather_events** - Statistical anomaly detection (Z-score based)

## Architecture

```mermaid
graph LR
    %% Styles
    classDef storage fill:#E1F5FE,stroke:#01579B,stroke-width:2px;
    classDef compute fill:#FFF3E0,stroke:#E65100,stroke-width:2px;
    classDef orchestrator fill:#E8F5E9,stroke:#1B5E20,stroke-width:2px;
    classDef cicd fill:#F3E5F5,stroke:#4A148C,stroke-width:2px;

    subgraph "Local Dev"
        Dev[Developer]
        LocalDB[(Local DuckDB)]
    end

    subgraph "CI/CD Pipeline"
        GH[GitHub Repo]
        GHA["GitHub Actions
        (CI: Test / CD: Deploy)"]
    end

    subgraph "Orchestration"
        Prefect[Prefect Cloud/Server]
    end

    subgraph "Execution Plane"
        Agent[Prefect Agent/Runner]
        DuckDB["DuckDB Engine
        (dbt-duckdb)"]
    end

    subgraph "Data Lake"
        Iceberg[("Iceberg Tables
        S3/GCS")]
    end

    %% Flows
    Dev -->|Push Code| GH
    Dev -.->|Ad-hoc Query| LocalDB
    GH -->|Trigger| GHA
    GHA -->|Register Flow| Prefect
    Prefect -->|Schedule Run| Agent
    Agent -->|Spin up| DuckDB
    DuckDB -->|Read/Write| Iceberg

    %% Apply Styles
    class Iceberg,LocalDB storage;
    class DuckDB,Agent compute;
    class Prefect orchestrator;
    class GH,GHA cicd;
```

## Orchestration & Deployment

This project includes production-ready orchestration using **Prefect** and CI/CD with **GitHub Actions**.

### Prefect Flows

Four pre-configured workflows available on-demand or scheduled:
- **Demo Flow** - Simple demonstration of Prefect features
- **Weather Ingestion** - Fetches and loads weather data
- **dbt Transformations** - Runs dbt models and tests
- **Complete Pipeline** - End-to-end data pipeline

### GitHub Actions

Automated workflows for:
- ‚úÖ Code quality (Ruff linting & formatting)
- ‚úÖ Type checking (mypy)
- ‚úÖ Testing (pytest with coverage)
- ‚úÖ dbt validation (compile, parse, test)

## Learn More

See [CLAUDE.md](CLAUDE.md) for:
- Iceberg architecture deep-dive
- REST catalog implementation details
- Prefect orchestration & deployment
- GitHub Actions CI/CD setup
- Production deployment guide
- Troubleshooting & best practices

## Contributing

Contributions are welcome! Please read [CONTRIBUTING.md](../CONTRIBUTING.md) for:
- Development setup
- Code style guidelines
- Pull request process
- Testing requirements

## Project Highlights

‚ú® **What makes this project special:**

- **Custom REST Catalog**: Full implementation of Apache Iceberg REST spec
- **Production Orchestration**: Prefect with on-demand and scheduled flows
- **Modern Stack**: DuckDB 1.4.2+ with native Iceberg support
- **CI/CD Pipeline**: GitHub Actions for automated testing and validation
- **Clean Architecture**: Modular structure for easy contribution
- **Comprehensive Docs**: Both user guides and technical deep-dives

## Use Cases

This project demonstrates patterns for:
- Building data lakehouses with Apache Iceberg
- Implementing custom Iceberg catalogs
- Orchestrating data pipelines with Prefect
- Using dbt for data transformations
- Integrating DuckDB with Iceberg
- CI/CD for data pipelines

## Resources

- [Apache Iceberg](https://iceberg.apache.org/)
- [DuckDB Iceberg Extension](https://duckdb.org/docs/extensions/iceberg)
- [dbt Documentation](https://docs.getdbt.com/)
- [PyIceberg](https://py.iceberg.apache.org/)
- [Prefect Documentation](https://docs.prefect.io/)

## License

MIT License - feel free to use this project for learning and commercial purposes.

---

**Built with ‚ù§Ô∏è for the data engineering community**

*If you find this project helpful, please consider giving it a ‚≠ê on GitHub!*